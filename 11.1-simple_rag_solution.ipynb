{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "uiSPDftDJMWV",
        "bHrLhMMCJmvf",
        "_igGVJVT17cC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "324c698571a444dcb6ec4580eaa0f270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7623e1fefaac4f9ea13b176e3910581b",
              "IPY_MODEL_84553cb4990449c3b1df3a8821ade282",
              "IPY_MODEL_9053ac2f6d794232b223dd08fd9371e2"
            ],
            "layout": "IPY_MODEL_d53ef5e84e9848eaac18fc4686a061b2"
          }
        },
        "7623e1fefaac4f9ea13b176e3910581b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cb7ec4d859446a6bcd7bf26cf45124a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a5670c9337404859b8b73af4f848c482",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "84553cb4990449c3b1df3a8821ade282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43713c8b2d3e4ac5bf077e3de0c86d98",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fc75510f290495684af37a3877583a4",
            "value": 8
          }
        },
        "9053ac2f6d794232b223dd08fd9371e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33046eb89ac4059a39028fbaa330785",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_39fdcb2576764d1c8775f84a274dbe2c",
            "value": "â€‡8/8â€‡[01:15&lt;00:00,â€‡â€‡8.83s/it]"
          }
        },
        "d53ef5e84e9848eaac18fc4686a061b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cb7ec4d859446a6bcd7bf26cf45124a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5670c9337404859b8b73af4f848c482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43713c8b2d3e4ac5bf077e3de0c86d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc75510f290495684af37a3877583a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f33046eb89ac4059a39028fbaa330785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39fdcb2576764d1c8775f84a274dbe2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Kratak uvod u RAG koristeÄ‡i LangChain i HuggingFace\n",
        "\n",
        "**Retrieval-augmented generation**, skraÄ‡eno RAG, je tehnika koja poboljÅ¡ava pouzdanost generativnih modela sa moguÄ‡nostima pronalaÅ¾enja (retrieval).\n",
        "\n",
        "RAG koristimo da dopunimo velike jeziÄke modele, skraÄ‡eno VJM tj. LLM - Large Language Model, tako Å¡to im na taj naÄin omoguÄ‡avamo pristup relevantnim informacijama iz spoljnih izvora, poboljÅ¡avajuÄ‡i time sposobnost VJM modela da generiÅ¡e odgovore koji su relevantni i taÄni za zadane upite.\n",
        "\n",
        "Pogledajte ilustraciju:\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1qRU-B8TjYDz8ANRB7Y1lPwIRdehijurL)\n",
        "\n",
        "**Izvor za ilustraciju:** [DataKolektiv](https://datakolektiv.com/)\n",
        "\n",
        "\n",
        "\n",
        "1. **Embeddings**  \n",
        "  *Embeddings* predstavlja vektorsku reprezentaciju, u naÅ¡em sluÄaju, teksta.\n",
        "2. **Prompt + Query**  \n",
        "  *Prompt* predstavlja poÄetni upit koju korisnik postavlja LLM modelu, a *query* je konkretno pitanje ili zahtjev koji se postavlja.\n",
        "3. **Query Embedding**  \n",
        "  *Query Embedding* je vektorska reprezentacija upita. Ovaj vektor se koristi za pretraÅ¾ivanje relevantnih dokumenata u vektorskoj reprezentaciji.\n",
        "4. **Relevant Context Documents**  \n",
        "  *Relevant Context Documents* su dokumenti ili informacije iz baze koje su relevantne za postavljeni upit.\n",
        "5. **Enhanced Prompt**  \n",
        "  *Enhanced Prompt* je verzija osnovnog prompta koja ukljuÄuje informacije iz relevantnih dokumenata, odnosno sadrÅ¾i kontekst koji Ä‡e LLM-u pomoÄ‡i prilikom generisanja odgovora. Ovaj odgovor je rezultat RAG sistema koji kombinuje informacije iz poÄetnog prompta, korisniÄkog upita i odgovarajuÄ‡eg konteksta."
      ],
      "metadata": {
        "id": "95sKK-a27v-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zadatak\n",
        "\n",
        "VaÅ¡ zadatak je da kreirate RAG koristeÄ‡i HuggingFace (za javno dostupne modele) i LangChain.\n",
        "\n",
        "**Koraci:**\n",
        "\n",
        "0. Instalacija potrebnih paketa\n",
        "1. UÄitavanje i priprema podataka (dokumenata)\n",
        "2. Kreiranje vektorske baze i retrivera  \n",
        "3. UÄitavanje LLM modela\n",
        "4. Definisanje pipeline-a\n",
        "\n",
        "\n",
        "**Napomene:**\n",
        "\n",
        "\n",
        "*   Koristite dokumentaciju:\n",
        "  * [HuggingFace Transformers](https://huggingface.co/docs/transformers/en/index)\n",
        "  * [HuggingFace Hub](https://huggingface.co/docs/hub/index)\n",
        "  * [LangChain](https://python.langchain.com/docs/get_started/introduction)\n",
        "*   MoÅ¾ete koristiti ChatGPT i Copilot (ex. Bing Chat) ğŸ¤–"
      ],
      "metadata": {
        "id": "oJPVoFSiFI7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instalacija potrebnih paketa"
      ],
      "metadata": {
        "id": "uiSPDftDJMWV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T5L906l8sSH",
        "outputId": "86597801-8ba3-4523-a8c8-a5ee68b0eafa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q torch transformers accelerate bitsandbytes sentence-transformers faiss-gpu\n",
        "!pip install -q langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q arxiv\n",
        "!pip install -q pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D60YGkCkOdl",
        "outputId": "04d62691-0dcd-473f-feaf-2a7297fbcad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/81.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### UÄitavanje i priprema podataka\n",
        "\n",
        "Koristite *LangChain* za uÄitavanje dokumenata ili nekog drugog tekstualnog sadrÅ¾aja nad kojim Å¾elite izvrÅ¡avati upite - [link](https://python.langchain.com/docs/integrations/document_loaders/).\n",
        "\n",
        "Kada odaberete podatke koje Ä‡ete koristiti, potrebno je da ih pripremite na odgovarajuÄ‡i naÄin za dalju obradu i Äuvanje u vektorskoj bazi.\n"
      ],
      "metadata": {
        "id": "oyc37Kd3JVyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import ArxivLoader\n",
        "\n",
        "document_id = \"1706.03762v1\" # inicijalna verzija rada Attention Is All You Need\n",
        "loader = ArxivLoader(query=document_id, load_max_docs=2)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "AqQRkadsgEZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Published - datum kada je dokument objavljen ili posljednji put izmijenjen\n",
        "docs[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv2AoQKllc6G",
        "outputId": "d20a2f9b-b57b-44e9-f295-b6a251b92009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Published': '2017-06-12',\n",
              " 'Title': 'Attention Is All You Need',\n",
              " 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin',\n",
              " 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=20)\n",
        "\n",
        "chunked_docs = doc_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "bYrlfcNDmRnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunked_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LHR6PT8nc_3",
        "outputId": "265e72d4-abeb-439d-959f-01501cbfd304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Kreiranje vektorske baze i *retriever*-a\n",
        "\n",
        "Izaberite vekrorsku bazu koju Ä‡ete koristiti za Äuvanje vektora (embedding-a) dokumenata, pregled podrÅ¾anih baza moÅ¾ete pronaÄ‡i na ovom [linku](https://python.langchain.com/docs/integrations/vectorstores/).\n",
        "\n",
        "Vektore trebate kreirati koristeÄ‡i otvorene embedding modele, potraÅ¾ite neki manji embedding model na HuggingFace Hub-u, referiÅ¡ite se na [Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)."
      ],
      "metadata": {
        "id": "T6Bw_uXgJaWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "\n",
        "# ovdje smo koristili osnovni bge (BAAI general embedding) model\n",
        "# dimenzija vektora ovog modela je 768\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
        "VECTOR_DB = FAISS.from_documents(chunked_docs, embeddings_model, distance_strategy=DistanceStrategy.COSINE)"
      ],
      "metadata": {
        "id": "lxOC0Y2ZnoHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = VECTOR_DB.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "M_7I_n4_oVIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### UÄitavanje LLM-a\n",
        "\n",
        "PotraÅ¾ite neki manji LLM model na HuggingFace Hub-u, referiÅ¡ite se na [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard). Cilj je da iskoristite model koji je optimizovan za brÅ¾e izvrÅ¡avanje.\n",
        "\n",
        "Prilikom instanciranja modela, moÅ¾ete koristiti konfiguracije koje optimizuju njegovo izvrÅ¡avanje kao Å¡to je kvantizacija (quantization).\n"
      ],
      "metadata": {
        "id": "3pu8rAYIJfgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# ucitavamo optimizovanu tj. kvantizovanu verziju LLM modela, radi brzeg izvrsavanja\n",
        "# LLM model koji koristimo je zasnovan na Mistral modelu\n",
        "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "324c698571a444dcb6ec4580eaa0f270",
            "7623e1fefaac4f9ea13b176e3910581b",
            "84553cb4990449c3b1df3a8821ade282",
            "9053ac2f6d794232b223dd08fd9371e2",
            "d53ef5e84e9848eaac18fc4686a061b2",
            "0cb7ec4d859446a6bcd7bf26cf45124a",
            "a5670c9337404859b8b73af4f848c482",
            "43713c8b2d3e4ac5bf077e3de0c86d98",
            "8fc75510f290495684af37a3877583a4",
            "f33046eb89ac4059a39028fbaa330785",
            "39fdcb2576764d1c8775f84a274dbe2c"
          ]
        },
        "id": "nY06nQfzor3X",
        "outputId": "b7beb960-af31-4be2-b66e-e71168444a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "324c698571a444dcb6ec4580eaa0f270"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Definisanje pipeline-a\n",
        "\n",
        "Koristite HuggingFace *transformers* biblioteku za konstruisanje lanca ili pipeline-a za generisanje teksta, ovaj korak ukljuÄuje postavljanje parametara kao Å¡to su prethodno definisani LLM model, tokenizator, temperatura i drugi.\n",
        "\n",
        "Potrebno je da definiÅ¡ete Å¡ablon za unos koristeÄ‡i *PromptTemplate*, na ovaj naÄin modelu dajete potrebne informacije o kontekstu i pitanju koje se postavlja.\n",
        "\n",
        "Na kraju je potrebno da poveÅ¾ete sve komponente lanca."
      ],
      "metadata": {
        "id": "bHrLhMMCJmvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from transformers import pipeline\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "text_generation_pipeline = pipeline(\n",
        "    model=llm_model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=400,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n",
        "# prompts\n",
        "\"\"\"\n",
        "#1\n",
        "Using the information contained in the context, give a comprehensive answer to\n",
        "the question. Respond only to the question asked, response should be concise and\n",
        " relevant to the question. Context is:\n",
        "\n",
        "#2\n",
        "Your task is to answer to the given question based on your knowledge. Use the following context:\n",
        "\n",
        "\"\"\"\n",
        "prompt_template = \"\"\"\n",
        "<|system|>\n",
        "Using the information contained in the context, give a comprehensive answer to\n",
        "the question. Respond only to the question asked, response should be concise and\n",
        " relevant to the question. Context is:\n",
        "{context}\n",
        "\n",
        "</s>\n",
        "<|user|>\n",
        "{question}\n",
        "</s>\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=prompt_template,\n",
        ")\n",
        "\n",
        "# povezivanje komponenata lanca\n",
        "llm_chain = prompt | llm | output_parser"
      ],
      "metadata": {
        "id": "pw96eAWdov9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "retriever = VECTOR_DB.as_retriever()\n",
        "\n",
        "components = {\n",
        "    \"context\": retriever,\n",
        "    \"question\": RunnablePassthrough()\n",
        "}\n",
        "\n",
        "rag_chain = components | llm_chain\n",
        "\n",
        "def invoke_rag_chain(question):\n",
        "  response = rag_chain.invoke(question)\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "sVbI6nqkqp2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testiranje"
      ],
      "metadata": {
        "id": "_igGVJVT17cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the name of proposed architecture?\""
      ],
      "metadata": {
        "id": "rK42KG3wqvdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_rag_chain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "_IzxBEB8sGk6",
        "outputId": "f873175a-0001-414a-ab4a-d0637e322289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The name of the proposed architecture is the Transformer, as described in the paper \"Attention Is All You Need\" by Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin (published on June 12, 2017). The Transformer is a simple network architecture based solely on attention mechanisms, which dispenses with recurrence and convolutions entirely and has shown superior performance in machine translation tasks compared to existing models.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is the main idea of attention?\""
      ],
      "metadata": {
        "id": "ABehZCCo0H5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_rag_chain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "P_pyHosX0IvY",
        "outputId": "25463c36-e36f-4231-9365-0161ff5d8e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In the context provided, the main idea of attention is a mechanism used in sequence transduction models, specifically in machine translation tasks, which allows the model to focus on specific parts of a sequence during processing. This mechanism, called self-attention, relates different positions of a single sequence to compute a representation of the sequence. It helps to improve the quality of the model\\'s output while making it more parallelizable and requiring less time to train compared to traditional sequence transduction models based on complex recurrent or convolutional neural networks. The authors of the paper \"Attention Is All You Need\" propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. The paper presents experimental results showing that their model outperforms existing best results in machine translation tasks, including ensembles, by significant margins. Overall, attention is a key component in modern sequence transduction models that enables them to process sequences more efficiently and accurately.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How did the writers evaluate the significance of certain architectural elements?\""
      ],
      "metadata": {
        "id": "QNjyGyEX0S0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_rag_chain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "mTRtY92z0U_l",
        "outputId": "4bd9eebd-18bf-4e11-ef56-39c6138cb960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The writers evaluated the significance of certain architectural elements through experiments and analysis. They varied the number of attention heads and the attention key and value dimensions, as well as the attention key size dk, and observed the impact on model quality. They also noted that some attention heads seemed to be involved in anaphora resolution, as evidenced by sharp attentions for specific words. Additionally, they found that bigger models were better and dropout was helpful in avoiding overfitting. These observations led them to suggest that determining compatibility may require a more sophisticated compatibility function than dot product. Overall, their experiments and analyses provided insights into the importance and effectiveness of various architectural elements in their proposed network architecture, the Transformer.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPEf438XZLHF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}